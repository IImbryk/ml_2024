## Домашнее задание 5



### Датасет

В этом домашнем задании мы используем датасет "Students Performance in 2024 JAMB" с [Kaggle](https://www.kaggle.com/datasets/idowuadamo/students-performance-in-2024-jamb).

### Подготовка датасета

Сначала преобразуем названия колонок к нижнему регистру:

```python
df.columns = df.columns.str.lower().str.replace(' ', '_')
```
### Подготовка

* Удалите столбец `student_id`.
* Заполните пропущенные значения нулями.
* Разделите данные на train/validation/test с распределением 60%/20%/20%.
* Используйте функцию `train_test_split`, установите `random_state=1`.
* Преобразуйте датафреймы в матрицы с помощью `DictVectorizer(sparse=True)`.


## Вопрос 1

Обучите дерево решений для предсказания переменной `jamb_score`.

* Обучите модель с `max_depth=1`.

Какой признак используется для разбиения данных?

* `study_hours_per_week`
* `attendance_rate`
* `teacher_quality`
* `distance_to_school`


## Вопрос 2

Обучите случайный лес с такими параметрами:

* `n_estimators=10`
* `random_state=1`
* `n_jobs=-1` (необязательно - для ускорения обучения)

Какое значение RMSE у этой модели на валидационных данных?

* 22.13
* 42.13
* 62.13
* 82.12


## Вопрос 3

Теперь поэкспериментируем с параметром `n_estimators`:

* Попробуйте значения этого параметра от 10 до 200 с шагом 10.
* Установите `random_state=1`.
* Оцените модель на валидационном наборе данных.

После какого значения `n_estimators` RMSE перестает улучшаться?
Учтите точность до 3 знаков после запятой.

- 10
- 25
- 80
- 200


## Вопрос 4

Выберите лучшее значение `max_depth`:

* Попробуйте значения `max_depth`: `[10, 15, 20, 25]`.
* Для каждого значения попробуйте `n_estimators` от 10 до 200 (с шагом 10).
* Рассчитайте среднее значение RMSE.
* Установите `random_state=1`.

Какое значение `max_depth` оказалось лучшим по среднему RMSE?

* 10
* 15
* 20
* 25


## Вопрос 5

Можно получить информацию о важности признаков из моделей, основанных на деревьях.

На каждом шаге алгоритма обучения дерева решений находится лучшее разбиение. При этом можно рассчитать "gain" — уменьшение нечистоты до и после разбиения. Это полезно для понимания важных признаков для моделей, основанных на деревьях.

В Scikit-Learn такие модели имеют эту информацию в атрибуте [`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_).

Для этого задания найдите самый важный признак:

* Обучите модель с такими параметрами:
  * `n_estimators=10`
  * `max_depth=20`
  * `random_state=1`
  * `n_jobs=-1` (необязательно)
* Найдите информацию о важности признаков.

Какой признак оказался самым важным (из этих четырех)?

* `study_hours_per_week`
* `attendance_rate`
* `distance_to_school`
* `teacher_quality`


## Вопрос 6

Теперь обучим модель XGBoost! В этом задании мы будем настраивать параметр `eta`:

* Установите XGBoost.
* Создайте DMatrix для train и validation.
* Создайте watchlist.
* Обучите модель с этими параметрами в течение 100 раундов:

```python
xgb_params = {
    'eta': 0.3, 
    'max_depth': 6,
    'min_child_weight': 1,
    
    'objective': 'reg:squarederror',
    'nthread': 8,
    
    'seed': 1,
    'verbosity': 1,
}
```
Теперь измените `eta` с 0.3 на 0.1.

Какое значение `eta` приводит к лучшему значению RMSE на валидационном наборе данных?
* 0.3
* 0.1
* Both give equal value
